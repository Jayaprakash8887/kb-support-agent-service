#!/bin/bash

# Script to create systemd services for 4 GPU Ollama instances

# Stop existing ollama service
sudo systemctl stop ollama
sudo systemctl disable ollama

# Create service file for GPU 0
sudo tee /etc/systemd/system/ollama-gpu0.service > /dev/null <<EOF
[Unit]
Description=Ollama AI Service GPU 0
After=network.target
Wants=network.target

[Service]
Type=simple
User=ollama
Group=ollama
WorkingDirectory=/usr/share/ollama
Environment="CUDA_VISIBLE_DEVICES=0"
Environment="OLLAMA_HOST=0.0.0.0:11434"
Environment="OLLAMA_MAX_LOADED_MODELS=1"
Environment="OLLAMA_NUM_PARALLEL=8"
Environment="OLLAMA_MAX_QUEUE=64"
Environment="OLLAMA_CONCURRENT_REQUESTS=12"
Environment="OLLAMA_NUM_THREADS=10"
Environment="OMP_NUM_THREADS=5"
Environment="OLLAMA_GPU_MEMORY_FRACTION=0.9"
Environment="OLLAMA_FLASH_ATTENTION=1"
Environment="OLLAMA_KV_CACHE_TYPE=q8_0"
Environment="OLLAMA_MMAP=1"
Environment="OLLAMA_NUMA=0"
Environment="CUDA_DEVICE_ORDER=PCI_BUS_ID"
ExecStart=/usr/local/bin/ollama serve
Restart=always
RestartSec=3
StandardOutput=journal
StandardError=journal
SyslogIdentifier=ollama-gpu0

[Install]
WantedBy=multi-user.target
EOF

# Create service file for GPU 1
sudo tee /etc/systemd/system/ollama-gpu1.service > /dev/null <<EOF
[Unit]
Description=Ollama AI Service GPU 1
After=network.target
Wants=network.target

[Service]
Type=simple
User=ollama
Group=ollama
WorkingDirectory=/usr/share/ollama
Environment="CUDA_VISIBLE_DEVICES=1"
Environment="OLLAMA_HOST=0.0.0.0:11435"
Environment="OLLAMA_MAX_LOADED_MODELS=1"
Environment="OLLAMA_NUM_PARALLEL=8"
Environment="OLLAMA_MAX_QUEUE=64"
Environment="OLLAMA_CONCURRENT_REQUESTS=12"
Environment="OLLAMA_NUM_THREADS=10"
Environment="OMP_NUM_THREADS=5"
Environment="OLLAMA_GPU_MEMORY_FRACTION=0.9"
Environment="OLLAMA_FLASH_ATTENTION=1"
Environment="OLLAMA_KV_CACHE_TYPE=q8_0"
Environment="OLLAMA_MMAP=1"
Environment="OLLAMA_NUMA=0"
Environment="CUDA_DEVICE_ORDER=PCI_BUS_ID"
ExecStart=/usr/local/bin/ollama serve
Restart=always
RestartSec=3
StandardOutput=journal
StandardError=journal
SyslogIdentifier=ollama-gpu1

[Install]
WantedBy=multi-user.target
EOF

# Create service file for GPU 2
sudo tee /etc/systemd/system/ollama-gpu2.service > /dev/null <<EOF
[Unit]
Description=Ollama AI Service GPU 2
After=network.target
Wants=network.target

[Service]
Type=simple
User=ollama
Group=ollama
WorkingDirectory=/usr/share/ollama
Environment="CUDA_VISIBLE_DEVICES=2"
Environment="OLLAMA_HOST=0.0.0.0:11436"
Environment="OLLAMA_MAX_LOADED_MODELS=1"
Environment="OLLAMA_NUM_PARALLEL=8"
Environment="OLLAMA_MAX_QUEUE=64"
Environment="OLLAMA_CONCURRENT_REQUESTS=12"
Environment="OLLAMA_NUM_THREADS=10"
Environment="OMP_NUM_THREADS=5"
Environment="OLLAMA_GPU_MEMORY_FRACTION=0.9"
Environment="OLLAMA_FLASH_ATTENTION=1"
Environment="OLLAMA_KV_CACHE_TYPE=q8_0"
Environment="OLLAMA_MMAP=1"
Environment="OLLAMA_NUMA=0"
Environment="CUDA_DEVICE_ORDER=PCI_BUS_ID"
ExecStart=/usr/local/bin/ollama serve
Restart=always
RestartSec=3
StandardOutput=journal
StandardError=journal
SyslogIdentifier=ollama-gpu2

[Install]
WantedBy=multi-user.target
EOF

# Create service file for GPU 3
sudo tee /etc/systemd/system/ollama-gpu3.service > /dev/null <<EOF
[Unit]
Description=Ollama AI Service GPU 3
After=network.target
Wants=network.target

[Service]
Type=simple
User=ollama
Group=ollama
WorkingDirectory=/usr/share/ollama
Environment="CUDA_VISIBLE_DEVICES=3"
Environment="OLLAMA_HOST=0.0.0.0:11437"
Environment="OLLAMA_MAX_LOADED_MODELS=1"
Environment="OLLAMA_NUM_PARALLEL=8"
Environment="OLLAMA_MAX_QUEUE=64"
Environment="OLLAMA_CONCURRENT_REQUESTS=12"
Environment="OLLAMA_NUM_THREADS=10"
Environment="OMP_NUM_THREADS=5"
Environment="OLLAMA_GPU_MEMORY_FRACTION=0.9"
Environment="OLLAMA_FLASH_ATTENTION=1"
Environment="OLLAMA_KV_CACHE_TYPE=q8_0"
Environment="OLLAMA_MMAP=1"
Environment="OLLAMA_NUMA=0"
Environment="CUDA_DEVICE_ORDER=PCI_BUS_ID"
ExecStart=/usr/local/bin/ollama serve
Restart=always
RestartSec=3
StandardOutput=journal
StandardError=journal
SyslogIdentifier=ollama-gpu3

[Install]
WantedBy=multi-user.target
EOF

# Reload systemd and enable services
sudo systemctl daemon-reload

# Enable and start all services
sudo systemctl enable ollama-gpu0.service
sudo systemctl enable ollama-gpu1.service
sudo systemctl enable ollama-gpu2.service
sudo systemctl enable ollama-gpu3.service

sudo systemctl start ollama-gpu0.service
sudo systemctl start ollama-gpu1.service
sudo systemctl start ollama-gpu2.service
sudo systemctl start ollama-gpu3.service

# Wait for services to start
sleep 10

# Check status of all services
echo "=== Service Status ==="
sudo systemctl status ollama-gpu0.service --no-pager -l
sudo systemctl status ollama-gpu1.service --no-pager -l
sudo systemctl status ollama-gpu2.service --no-pager -l
sudo systemctl status ollama-gpu3.service --no-pager -l

# Check if all ports are listening
echo "=== Port Status ==="
netstat -tlpn | grep -E "1143[4-7]"

# Check GPU utilization
echo "=== GPU Status ==="
nvidia-smi

echo "=== Service Management Commands ==="
echo "Check logs: sudo journalctl -u ollama-gpu0.service -f"
echo "Restart service: sudo systemctl restart ollama-gpu1.service"
echo "Stop all: sudo systemctl stop ollama-gpu{0..3}.service"
echo "Start all: sudo systemctl start ollama-gpu{0..3}.service"
echo "Status all: sudo systemctl status ollama-gpu{0..3}.service"